{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce53f93",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34236754",
   "metadata": {},
   "outputs": [],
   "source": [
    "### document Structure\n",
    "\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d06df09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'example.txt', 'author': 'Jitesh', 'page': 1, 'date_created': '2025-01-01'}, page_content='This is the main text content I am using to create RAG ')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = Document(\n",
    "    page_content=\"This is the main text content I am using to create RAG \",\n",
    "    metadata={\n",
    "        \"source\": \"example.txt\",\n",
    "        \"author\": \"Jitesh\",\n",
    "        \"page\": 1,\n",
    "        \"date_created\": \"2025-01-01\",\n",
    "    }\n",
    ")\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1777404b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a simple text document\n",
    "import os\n",
    "os.makedirs(\"../data/text_files\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b731ce47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sample text files created!\n"
     ]
    }
   ],
   "source": [
    "sample_texts={\n",
    "    \"../data/text_files/python_intro.txt\":\"\"\"Python Programming Introduction\n",
    "\n",
    "Python is a high-level, interpreted programming language known for its simplicity and readability.\n",
    "Created by Guido van Rossum and first released in 1991, Python has become one of the most popular\n",
    "programming languages in the world.\n",
    "\n",
    "Key Features:\n",
    "- Easy to learn and use\n",
    "- Extensive standard library\n",
    "- Cross-platform compatibility\n",
    "- Strong community support\n",
    "\n",
    "Python is widely used in web development, data science, artificial intelligence, and automation.\"\"\",\n",
    "    \n",
    "    \"../data/text_files/machine_learning.txt\": \"\"\"Machine Learning Basics\n",
    "\n",
    "Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
    "from experience without being explicitly programmed. It focuses on developing computer programs\n",
    "that can access data and use it to learn for themselves.\n",
    "\n",
    "Types of Machine Learning:\n",
    "1. Supervised Learning: Learning with labeled data\n",
    "2. Unsupervised Learning: Finding patterns in unlabeled data\n",
    "3. Reinforcement Learning: Learning through rewards and penalties\n",
    "\n",
    "Applications include image recognition, speech processing, and recommendation systems\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "}\n",
    "\n",
    "for filepath,content in sample_texts.items():\n",
    "    with open(filepath,'w',encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "print(\"✅ Sample text files created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b637de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': '../data/text_files/python_intro.txt'}, page_content='Python Programming Introduction\\n\\nPython is a high-level, interpreted programming language known for its simplicity and readability.\\nCreated by Guido van Rossum and first released in 1991, Python has become one of the most popular\\nprogramming languages in the world.\\n\\nKey Features:\\n- Easy to learn and use\\n- Extensive standard library\\n- Cross-platform compatibility\\n- Strong community support\\n\\nPython is widely used in web development, data science, artificial intelligence, and automation.')]\n"
     ]
    }
   ],
   "source": [
    "## Textloader\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"../data/text_files/python_intro.txt\", encoding=\"utf-8\")\n",
    "document=loader.load()\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5885b722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../data/text_files/python_intro.txt'}, page_content='Python Programming Introduction\\n\\nPython is a high-level, interpreted programming language known for its simplicity and readability.\\nCreated by Guido van Rossum and first released in 1991, Python has become one of the most popular\\nprogramming languages in the world.\\n\\nKey Features:\\n- Easy to learn and use\\n- Extensive standard library\\n- Cross-platform compatibility\\n- Strong community support\\n\\nPython is widely used in web development, data science, artificial intelligence, and automation.'),\n",
       " Document(metadata={'source': '../data/text_files/machine_learning.txt'}, page_content='Machine Learning Basics\\n\\nMachine learning is a subset of artificial intelligence that enables systems to learn and improve\\nfrom experience without being explicitly programmed. It focuses on developing computer programs\\nthat can access data and use it to learn for themselves.\\n\\nTypes of Machine Learning:\\n1. Supervised Learning: Learning with labeled data\\n2. Unsupervised Learning: Finding patterns in unlabeled data\\n3. Reinforcement Learning: Learning through rewards and penalties\\n\\nApplications include image recognition, speech processing, and recommendation systems\\n\\n\\n    ')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## directory loader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "dir_loader = DirectoryLoader(\n",
    "    \"../data/text_files\", \n",
    "    glob=\"**/*.txt\",\n",
    "    loader_cls=TextLoader, \n",
    "    loader_kwargs={\"encoding\": \"utf-8\"},\n",
    "    show_progress=False\n",
    ")\n",
    "documents=dir_loader.load()\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ace12247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-22T13:39:41+00:00', 'source': '../data/pdf_files/Jitesh_resume.pdf', 'file_path': '../data/pdf_files/Jitesh_resume.pdf', 'total_pages': 1, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-22T13:39:41+00:00', 'trapped': '', 'modDate': 'D:20250822133941Z', 'creationDate': 'D:20250822133941Z', 'page': 0}, page_content='Jitesh Kumar\\njitesh.me | jitesh.kumar05official@gmail.com | LinkedIn | GitHub | +91 6397983037\\nEducation\\nAnurag University\\nCGPA: 8.74/10\\nBachelor of Technology in Information Technology\\n2023 – 2027\\nKendriya Vidyalaya Picket, Hyderabad\\nPercentage: 81%\\nCBSE 12th\\n2021 – 2023\\nProjects\\nGo To Buddy – AI-Powered Desktop Assistant | Link\\n• Engineered a multi-threaded desktop assistant using Python & PyQt6 to ensure low-latency, real-time\\nresponsiveness for voice commands.\\n• Arch: PyQt6 UI →Multi-threaded Backend →GenAI (GitHub Models) & TTS (Murf AI) APIs.\\nStudent Performance Prediction Web App | Link\\n• Developed a full-stack ML service using Python & Flask with a scikit-learn model achieving 88%+ prediction\\naccuracy.\\n• Ops: Containerized the application with Docker and deployed a scalable MLOps pipeline on AWS and Azure.\\nGeeksforGeeks AUSC Chapter Website | Link\\n• Launched a full-stack portal serving 4000+ students using JavaScript and Firebase (Authentication & Firestore)\\nfor real-time updates.\\nTechnical Skills\\nLanguages: Python, C++ (DSA), JavaScript, SQL\\nTechnologies: Machine Learning, Deep Learning, Generative AI, AWS, Azure, Docker, Git\\nFrameworks: React.js, Next.js, Node.js, PyQt6, Flask, scikit-learn, PyTorch\\nCS Fundamentals: Computer Networks (TCP/IP), Operating Systems (OS), DBMS\\nLeadership Roles\\nBeta - Microsoft Learn Student Ambassador (MLSA)\\nJul 2025 – Present\\nAnurag University Chapter\\nVice Chair - IEEE SSIT\\nJan 2025 – Present\\nAnurag University Chapter\\nAchievements & Competitions\\n• Top 10 India Finalist & People’s Choice Award, Murf AI Hackathon (National, 2024)\\n• 1st Runners-Up, Data Dynamo Hackathon (University, 2024)\\n• 2nd Runners-Up, Innovasia (University, 2023)\\n• DSA & Competitive Programming: Solved 500+ problems (350+ on LeetCode, peak rating 1564).\\nCertifications\\nGoogle AI Essentials | Link\\nNetworking Basics – NATCAD | Link\\nInfosys Springboard: Data Structures | Link\\nProfiles\\nLeetCode (350+, Rating 1564) · HackerRank · Codolio · GeeksforGeeks')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "## load all the text files from the directory\n",
    "dir_loader=DirectoryLoader(\n",
    "    \"../data/pdf_files\",\n",
    "    glob=\"**/*.pdf\",\n",
    "    loader_cls=PyMuPDFLoader,\n",
    "    show_progress=False\n",
    "\n",
    ")\n",
    "\n",
    "pdf_documents=dir_loader.load()\n",
    "pdf_documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e5d310e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pdf_documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e0f053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Text splitting get into chunks\n",
    "\n",
    "def split_documents(documents,chunk_size=1000,chunk_overlap=200):\n",
    "    \"\"\"Split documents into smaller chunks for better RAG performance\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "    \n",
    "    # Show example of a chunk\n",
    "    if split_docs:\n",
    "        print(f\"\\nExample chunk:\")\n",
    "        print(f\"Content: {split_docs[0].page_content[:200]}...\")\n",
    "        print(f\"Metadata: {split_docs[0].metadata}\")\n",
    "    \n",
    "    return split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c721a71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 documents into 3 chunks\n",
      "\n",
      "Example chunk:\n",
      "Content: Jitesh Kumar\n",
      "jitesh.me | jitesh.kumar05official@gmail.com | LinkedIn | GitHub | +91 6397983037\n",
      "Education\n",
      "Anurag University\n",
      "CGPA: 8.74/10\n",
      "Bachelor of Technology in Information Technology\n",
      "2023 – 2027\n",
      "Ke...\n",
      "Metadata: {'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-22T13:39:41+00:00', 'source': '../data/pdf_files/Jitesh_resume.pdf', 'file_path': '../data/pdf_files/Jitesh_resume.pdf', 'total_pages': 1, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-22T13:39:41+00:00', 'trapped': '', 'modDate': 'D:20250822133941Z', 'creationDate': 'D:20250822133941Z', 'page': 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-22T13:39:41+00:00', 'source': '../data/pdf_files/Jitesh_resume.pdf', 'file_path': '../data/pdf_files/Jitesh_resume.pdf', 'total_pages': 1, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-22T13:39:41+00:00', 'trapped': '', 'modDate': 'D:20250822133941Z', 'creationDate': 'D:20250822133941Z', 'page': 0}, page_content='Jitesh Kumar\\njitesh.me | jitesh.kumar05official@gmail.com | LinkedIn | GitHub | +91 6397983037\\nEducation\\nAnurag University\\nCGPA: 8.74/10\\nBachelor of Technology in Information Technology\\n2023 – 2027\\nKendriya Vidyalaya Picket, Hyderabad\\nPercentage: 81%\\nCBSE 12th\\n2021 – 2023\\nProjects\\nGo To Buddy – AI-Powered Desktop Assistant | Link\\n• Engineered a multi-threaded desktop assistant using Python & PyQt6 to ensure low-latency, real-time\\nresponsiveness for voice commands.\\n• Arch: PyQt6 UI →Multi-threaded Backend →GenAI (GitHub Models) & TTS (Murf AI) APIs.\\nStudent Performance Prediction Web App | Link\\n• Developed a full-stack ML service using Python & Flask with a scikit-learn model achieving 88%+ prediction\\naccuracy.\\n• Ops: Containerized the application with Docker and deployed a scalable MLOps pipeline on AWS and Azure.\\nGeeksforGeeks AUSC Chapter Website | Link\\n• Launched a full-stack portal serving 4000+ students using JavaScript and Firebase (Authentication & Firestore)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-22T13:39:41+00:00', 'source': '../data/pdf_files/Jitesh_resume.pdf', 'file_path': '../data/pdf_files/Jitesh_resume.pdf', 'total_pages': 1, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-22T13:39:41+00:00', 'trapped': '', 'modDate': 'D:20250822133941Z', 'creationDate': 'D:20250822133941Z', 'page': 0}, page_content='GeeksforGeeks AUSC Chapter Website | Link\\n• Launched a full-stack portal serving 4000+ students using JavaScript and Firebase (Authentication & Firestore)\\nfor real-time updates.\\nTechnical Skills\\nLanguages: Python, C++ (DSA), JavaScript, SQL\\nTechnologies: Machine Learning, Deep Learning, Generative AI, AWS, Azure, Docker, Git\\nFrameworks: React.js, Next.js, Node.js, PyQt6, Flask, scikit-learn, PyTorch\\nCS Fundamentals: Computer Networks (TCP/IP), Operating Systems (OS), DBMS\\nLeadership Roles\\nBeta - Microsoft Learn Student Ambassador (MLSA)\\nJul 2025 – Present\\nAnurag University Chapter\\nVice Chair - IEEE SSIT\\nJan 2025 – Present\\nAnurag University Chapter\\nAchievements & Competitions\\n• Top 10 India Finalist & People’s Choice Award, Murf AI Hackathon (National, 2024)\\n• 1st Runners-Up, Data Dynamo Hackathon (University, 2024)\\n• 2nd Runners-Up, Innovasia (University, 2023)\\n• DSA & Competitive Programming: Solved 500+ problems (350+ on LeetCode, peak rating 1564).\\nCertifications'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-22T13:39:41+00:00', 'source': '../data/pdf_files/Jitesh_resume.pdf', 'file_path': '../data/pdf_files/Jitesh_resume.pdf', 'total_pages': 1, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-22T13:39:41+00:00', 'trapped': '', 'modDate': 'D:20250822133941Z', 'creationDate': 'D:20250822133941Z', 'page': 0}, page_content='• 2nd Runners-Up, Innovasia (University, 2023)\\n• DSA & Competitive Programming: Solved 500+ problems (350+ on LeetCode, peak rating 1564).\\nCertifications\\nGoogle AI Essentials | Link\\nNetworking Basics – NATCAD | Link\\nInfosys Springboard: Data Structures | Link\\nProfiles\\nLeetCode (350+, Rating 1564) · HackerRank · Codolio · GeeksforGeeks')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "chunks=split_documents(pdf_documents)\n",
    "chunks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3445bebd",
   "metadata": {},
   "source": [
    "## Embedding and VectorStoreDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "108070a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List,Dict, Any,Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31cf756d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n",
      "Model loaded successfully. embedding dimension: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x7f8e2015c110>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "    \"\"\"Handles Document Embedding using SentenceTransformers and stores in ChromaDB\"\"\"\n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        \"\"\"\n",
    "        Initializes the EmbeddingManager.\n",
    "        Args:\n",
    "            model_name: Hugging Face model name for sentence embeddings.\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model=None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        \"\"\"Loads the SentenceTransformer model.\"\"\"\n",
    "        try:\n",
    "            print(f\"Loading embedding model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model loaded successfully. embedding dimension: {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generates embeddings for a list of texts.\n",
    "        Args:\n",
    "            texts: List of text strings to embed.\n",
    "        Returns:\n",
    "            Numpy array of embeddings.\n",
    "        \"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded.\")\n",
    "        print(f\"Generating embeddings for {len(texts)} texts...\")\n",
    "        embeddings = self.model.encode(texts, convert_to_numpy=True)\n",
    "        print(f\"Generated embeddings with shape: {embeddings.shape}\")\n",
    "        return embeddings\n",
    "    \n",
    "    \n",
    "\n",
    "## initialize Embedding Manager\n",
    "embedding_manager=EmbeddingManager()\n",
    "embedding_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae7fd4c",
   "metadata": {},
   "source": [
    "## VectorStoreDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c76bd282",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorStoreDB:\n",
    "    \"\"\"Manages a vector store using ChromaDB.\"\"\"\n",
    "    def __init__(self, collection_name: str = \"pdf_documents\", persist_directory: str = \"../data/vector_store/\"):\n",
    "        \"\"\"\n",
    "        Initializes the VectorStoreDB.\n",
    "        Args:\n",
    "            collection_name: Name of the ChromaDB collection.\n",
    "            persist_directory: Directory to persist the vector store.\n",
    "        \"\"\"\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client=None\n",
    "        self.collection=None\n",
    "        self._initialize_db()\n",
    "    def _initialize_db(self):\n",
    "        \"\"\"Initializes the ChromaDB client and collection.\"\"\"\n",
    "        try:\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name=self.collection_name,\n",
    "                metadata={\"description\": \"pdf document embeddings for RAG\"}  # assuming embedding dim is 384\n",
    "                )\n",
    "            print(f\"VectorStoreDB initialized with collection: {self.collection_name}\")\n",
    "            print(f\"Existing documents in collection: {self.collection.count()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing VectorStoreDB: {e}\")\n",
    "            raise\n",
    "\n",
    "    def add_documents(self, documents: List[Document], embeddings: np.ndarray):\n",
    "        \"\"\"\n",
    "        Adds documents and their embeddings to the ChromaDB collection.\n",
    "        Args:\n",
    "            documents: List of Document objects to add.\n",
    "            embeddings: Numpy array of embeddings corresponding to the documents.\n",
    "        \"\"\"\n",
    "        if(len(documents) != embeddings.shape[0]):\n",
    "            raise ValueError(\"Number of documents and embeddings must match.\")\n",
    "        \n",
    "        print(f\"Adding {len(documents)} documents to the vector store...\")\n",
    "\n",
    "        #prepare data for insertion\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        document_texts = []\n",
    "        embedding_list = []\n",
    "\n",
    "        for i, (doc, emb) in enumerate(zip(documents, embeddings)):\n",
    "            doc_id = str(uuid.uuid4())\n",
    "            ids.append(doc_id)\n",
    "            metadatas.append(doc.metadata)\n",
    "            document_texts.append(doc.page_content)\n",
    "            embedding_list.append(emb.tolist())\n",
    "\n",
    "        self.collection.add(\n",
    "            ids=ids,\n",
    "            metadatas=metadatas,\n",
    "            documents=document_texts,\n",
    "            embeddings=embedding_list\n",
    "        )\n",
    "        print(f\"Documents added successfully. Total documents in collection: {self.collection.count()}\")\n",
    "    def similarity_search(self, query: str, top_k: int = 5) -> List[Tuple[Document, float]]:\n",
    "        \"\"\"\n",
    "        Performs a similarity search in the vector store.\n",
    "        Args:\n",
    "            query: The query string to search for.\n",
    "            top_k: The number of top similar documents to return.\n",
    "        Returns:\n",
    "            A list of tuples containing the matching documents and their similarity scores.\n",
    "        \"\"\"\n",
    "        query_embedding = self._embed_query(query)\n",
    "        results = self.collection.query(\n",
    "            query_embeddings=query_embedding,\n",
    "            n_results=top_k\n",
    "        )\n",
    "        return [(Document(page_content=res.document, metadata=res.metadata), res.score) for res in results]\n",
    "    def _embed_query(self, query: str) -> List[float]:\n",
    "        \"\"\"Embeds the query string using the embedding model.\"\"\"\n",
    "        if not embedding_manager.model:\n",
    "            raise ValueError(\"Embedding model not loaded.\")\n",
    "        return embedding_manager.model.encode([query], convert_to_numpy=True)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b735fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VectorStoreDB initialized with collection: pdf_documents\n",
      "Existing documents in collection: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStoreDB at 0x7f8dd69cb050>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore=VectorStoreDB()\n",
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c16fd2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-22T13:39:41+00:00', 'source': '../data/pdf_files/Jitesh_resume.pdf', 'file_path': '../data/pdf_files/Jitesh_resume.pdf', 'total_pages': 1, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-22T13:39:41+00:00', 'trapped': '', 'modDate': 'D:20250822133941Z', 'creationDate': 'D:20250822133941Z', 'page': 0}, page_content='Jitesh Kumar\\njitesh.me | jitesh.kumar05official@gmail.com | LinkedIn | GitHub | +91 6397983037\\nEducation\\nAnurag University\\nCGPA: 8.74/10\\nBachelor of Technology in Information Technology\\n2023 – 2027\\nKendriya Vidyalaya Picket, Hyderabad\\nPercentage: 81%\\nCBSE 12th\\n2021 – 2023\\nProjects\\nGo To Buddy – AI-Powered Desktop Assistant | Link\\n• Engineered a multi-threaded desktop assistant using Python & PyQt6 to ensure low-latency, real-time\\nresponsiveness for voice commands.\\n• Arch: PyQt6 UI →Multi-threaded Backend →GenAI (GitHub Models) & TTS (Murf AI) APIs.\\nStudent Performance Prediction Web App | Link\\n• Developed a full-stack ML service using Python & Flask with a scikit-learn model achieving 88%+ prediction\\naccuracy.\\n• Ops: Containerized the application with Docker and deployed a scalable MLOps pipeline on AWS and Azure.\\nGeeksforGeeks AUSC Chapter Website | Link\\n• Launched a full-stack portal serving 4000+ students using JavaScript and Firebase (Authentication & Firestore)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-22T13:39:41+00:00', 'source': '../data/pdf_files/Jitesh_resume.pdf', 'file_path': '../data/pdf_files/Jitesh_resume.pdf', 'total_pages': 1, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-22T13:39:41+00:00', 'trapped': '', 'modDate': 'D:20250822133941Z', 'creationDate': 'D:20250822133941Z', 'page': 0}, page_content='GeeksforGeeks AUSC Chapter Website | Link\\n• Launched a full-stack portal serving 4000+ students using JavaScript and Firebase (Authentication & Firestore)\\nfor real-time updates.\\nTechnical Skills\\nLanguages: Python, C++ (DSA), JavaScript, SQL\\nTechnologies: Machine Learning, Deep Learning, Generative AI, AWS, Azure, Docker, Git\\nFrameworks: React.js, Next.js, Node.js, PyQt6, Flask, scikit-learn, PyTorch\\nCS Fundamentals: Computer Networks (TCP/IP), Operating Systems (OS), DBMS\\nLeadership Roles\\nBeta - Microsoft Learn Student Ambassador (MLSA)\\nJul 2025 – Present\\nAnurag University Chapter\\nVice Chair - IEEE SSIT\\nJan 2025 – Present\\nAnurag University Chapter\\nAchievements & Competitions\\n• Top 10 India Finalist & People’s Choice Award, Murf AI Hackathon (National, 2024)\\n• 1st Runners-Up, Data Dynamo Hackathon (University, 2024)\\n• 2nd Runners-Up, Innovasia (University, 2023)\\n• DSA & Competitive Programming: Solved 500+ problems (350+ on LeetCode, peak rating 1564).\\nCertifications'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-22T13:39:41+00:00', 'source': '../data/pdf_files/Jitesh_resume.pdf', 'file_path': '../data/pdf_files/Jitesh_resume.pdf', 'total_pages': 1, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-22T13:39:41+00:00', 'trapped': '', 'modDate': 'D:20250822133941Z', 'creationDate': 'D:20250822133941Z', 'page': 0}, page_content='• 2nd Runners-Up, Innovasia (University, 2023)\\n• DSA & Competitive Programming: Solved 500+ problems (350+ on LeetCode, peak rating 1564).\\nCertifications\\nGoogle AI Essentials | Link\\nNetworking Basics – NATCAD | Link\\nInfosys Springboard: Data Structures | Link\\nProfiles\\nLeetCode (350+, Rating 1564) · HackerRank · Codolio · GeeksforGeeks')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c68b26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert the text to embeddings\n",
    "\n",
    "texts = [doc.page_content for doc in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68115f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jitesh Kumar\\njitesh.me | jitesh.kumar05official@gmail.com | LinkedIn | GitHub | +91 6397983037\\nEducation\\nAnurag University\\nCGPA: 8.74/10\\nBachelor of Technology in Information Technology\\n2023 – 2027\\nKendriya Vidyalaya Picket, Hyderabad\\nPercentage: 81%\\nCBSE 12th\\n2021 – 2023\\nProjects\\nGo To Buddy – AI-Powered Desktop Assistant | Link\\n• Engineered a multi-threaded desktop assistant using Python & PyQt6 to ensure low-latency, real-time\\nresponsiveness for voice commands.\\n• Arch: PyQt6 UI →Multi-threaded Backend →GenAI (GitHub Models) & TTS (Murf AI) APIs.\\nStudent Performance Prediction Web App | Link\\n• Developed a full-stack ML service using Python & Flask with a scikit-learn model achieving 88%+ prediction\\naccuracy.\\n• Ops: Containerized the application with Docker and deployed a scalable MLOps pipeline on AWS and Azure.\\nGeeksforGeeks AUSC Chapter Website | Link\\n• Launched a full-stack portal serving 4000+ students using JavaScript and Firebase (Authentication & Firestore)',\n",
       " 'GeeksforGeeks AUSC Chapter Website | Link\\n• Launched a full-stack portal serving 4000+ students using JavaScript and Firebase (Authentication & Firestore)\\nfor real-time updates.\\nTechnical Skills\\nLanguages: Python, C++ (DSA), JavaScript, SQL\\nTechnologies: Machine Learning, Deep Learning, Generative AI, AWS, Azure, Docker, Git\\nFrameworks: React.js, Next.js, Node.js, PyQt6, Flask, scikit-learn, PyTorch\\nCS Fundamentals: Computer Networks (TCP/IP), Operating Systems (OS), DBMS\\nLeadership Roles\\nBeta - Microsoft Learn Student Ambassador (MLSA)\\nJul 2025 – Present\\nAnurag University Chapter\\nVice Chair - IEEE SSIT\\nJan 2025 – Present\\nAnurag University Chapter\\nAchievements & Competitions\\n• Top 10 India Finalist & People’s Choice Award, Murf AI Hackathon (National, 2024)\\n• 1st Runners-Up, Data Dynamo Hackathon (University, 2024)\\n• 2nd Runners-Up, Innovasia (University, 2023)\\n• DSA & Competitive Programming: Solved 500+ problems (350+ on LeetCode, peak rating 1564).\\nCertifications',\n",
       " '• 2nd Runners-Up, Innovasia (University, 2023)\\n• DSA & Competitive Programming: Solved 500+ problems (350+ on LeetCode, peak rating 1564).\\nCertifications\\nGoogle AI Essentials | Link\\nNetworking Basics – NATCAD | Link\\nInfosys Springboard: Data Structures | Link\\nProfiles\\nLeetCode (350+, Rating 1564) · HackerRank · Codolio · GeeksforGeeks']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b73da1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 3 texts...\n",
      "Generated embeddings with shape: (3, 384)\n",
      "Adding 3 documents to the vector store...\n",
      "Documents added successfully. Total documents in collection: 3\n"
     ]
    }
   ],
   "source": [
    "## generate embeddings\n",
    "embeddings=embedding_manager.generate_embeddings(texts)\n",
    "\n",
    "## store in the vector store\n",
    "vectorstore.add_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183453b3",
   "metadata": {},
   "source": [
    "## RAG retrieval pipeline and vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2060645",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'document'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m## RAG retrieval pipeline and vector store\u001b[39;00m\n\u001b[32m     24\u001b[39m retriever=RAGRetriever(vectorstore,embedding_manager)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43mretriever\u001b[49m\u001b[43m.\u001b[49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is Python programming?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mRAGRetriever.retrieve\u001b[39m\u001b[34m(self, query, top_k)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mretrieve\u001b[39m(\u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, top_k: \u001b[38;5;28mint\u001b[39m = \u001b[32m5\u001b[39m) -> List[Tuple[Document, \u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[32m     14\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m    Retrieves the most relevant documents for a given query.\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m \u001b[33;03m        A list of tuples containing the matching documents and their similarity scores.\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvector_store\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 77\u001b[39m, in \u001b[36mVectorStoreDB.similarity_search\u001b[39m\u001b[34m(self, query, top_k)\u001b[39m\n\u001b[32m     72\u001b[39m query_embedding = \u001b[38;5;28mself\u001b[39m._embed_query(query)\n\u001b[32m     73\u001b[39m results = \u001b[38;5;28mself\u001b[39m.collection.query(\n\u001b[32m     74\u001b[39m     query_embeddings=query_embedding,\n\u001b[32m     75\u001b[39m     n_results=top_k\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDocument\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mres\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mres\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mres\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 77\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     72\u001b[39m query_embedding = \u001b[38;5;28mself\u001b[39m._embed_query(query)\n\u001b[32m     73\u001b[39m results = \u001b[38;5;28mself\u001b[39m.collection.query(\n\u001b[32m     74\u001b[39m     query_embeddings=query_embedding,\n\u001b[32m     75\u001b[39m     n_results=top_k\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [(Document(page_content=\u001b[43mres\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdocument\u001b[49m, metadata=res.metadata), res.score) \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results]\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'document'"
     ]
    }
   ],
   "source": [
    "class RAGRetriever:\n",
    "    \"\"\"Handles Query based retrieval from the vector store\"\"\"\n",
    "    def __init__(self, vectorStore: VectorStoreDB, embedding_manager: EmbeddingManager):\n",
    "        \"\"\"\n",
    "        Initializes the RAGRetriever.\n",
    "        Args:\n",
    "            vector_store: An instance of VectorStoreDB to perform retrieval from.\n",
    "            embedding_manager: An instance of EmbeddingManager to handle query embeddings.\n",
    "        \"\"\"\n",
    "        self.vector_store = vectorStore\n",
    "        self.embedding_manager = embedding_manager\n",
    "\n",
    "    def retrieve(self, query: str, top_k: int = 5, score_threshold: float = 0.0) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Retrieves the most relevant documents for a given query.\n",
    "        Args:\n",
    "            query: The query string to search for.\n",
    "            top_k: The number of top similar documents to return.\n",
    "            score_threshold: Minimum similarity score to consider a document relevant.\n",
    "        Returns:\n",
    "            A list of dictionaries containing the matching documents and their similarity scores.\n",
    "        \"\"\"\n",
    "        print(f\"Retrieving documents for query: '{query}'\")\n",
    "        print(f\"Using top_k={top_k} and score_threshold={score_threshold}\")\n",
    "        query_embedding = self.embedding_manager.embed_query(query)\n",
    "        try:\n",
    "            results = self.vector_store.collection.query(\n",
    "                query_embeddings=[query_embedding.tolist()],\n",
    "                n_results=top_k\n",
    "            )\n",
    "            retrieved_docs = []\n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                for doc, score, metadata in zip(results['documents'][0], results['distances'][0], results['metadatas'][0]):\n",
    "                    if score >= score_threshold:\n",
    "                        retrieved_docs.append({\n",
    "                            \"document\": doc,\n",
    "                            \"score\": score,\n",
    "                            \"metadata\": metadata\n",
    "                        })\n",
    "            print(f\"Retrieved {len(retrieved_docs)} documents above the score threshold.\")\n",
    "            return retrieved_docs\n",
    "        except Exception as e:\n",
    "            print(f\"Error during retrieval: {e}\")\n",
    "            return []\n",
    "retriever=RAGRetriever(vectorstore,embedding_manager)\n",
    "retriever.retrieve(\"What is Python programming?\", top_k=3, score_threshold=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c432b79f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-learn-bas1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
